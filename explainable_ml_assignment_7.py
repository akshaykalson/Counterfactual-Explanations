# -*- coding: utf-8 -*-
"""Explainable ML_Assignment 7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13C0-EbJlBQdyzzgagL59qB9vhBN0wOII
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics
from sklearn.model_selection import train_test_split
import tensorflow as tf

data = pd.read_csv('/content/recidivism-risk.csv',sep=',',encoding='latin-1')

print(data)

X = data.copy()
y = X['compas_score']
X = X.drop(['ID'], axis=1)
recidivism_df = pd.DataFrame(X)

cf_matrix = metrics.confusion_matrix(recidivism_df.is_recid, recidivism_df.compas_score)

plt.figure(figsize=(6,5))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot = True, fmt = '.2%', cmap = 'Blues', annot_kws={'size':16})

recidivism_c_df = recidivism_df[recidivism_df['race_Caucasian'] == 1]
recidivism_aa_df = recidivism_df[recidivism_df['race_African-American'] == 1]

cf_c_matrix = metrics.confusion_matrix(recidivism_c_df.is_recid,\
recidivism_c_df.compas_score)
cf_aa_matrix = metrics.confusion_matrix(recidivism_aa_df.is_recid,\
recidivism_aa_df.compas_score)

plt.figure(figsize=(6, 5))
plt.title("heatmap race_Caucasian\nrecidivated compas_score\n")
sns.heatmap(cf_c_matrix/np.sum(cf_c_matrix), annot=True,\
fmt='.2%', cmap='Blues', annot_kws={'va':'center','size':20, 'color':'red'})
plt.show()
plt.figure(figsize=(6, 5))
plt.title("heatmap race_African-American\nrecidivated compas_score\n")
sns.heatmap(cf_aa_matrix/np.sum(cf_aa_matrix), annot=True,\
fmt='.2%', cmap='Blues', annot_kws={'va':'center','size':20, 'color':'red'})
plt.show()

rand = 9
y = recidivism_df['compas_score']
X = recidivism_df.drop(['compas_score', 'is_recid'], axis=1).copy()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand)

!pip install catboost
from catboost import CatBoostClassifier
rand = 9
np.random.seed(rand)
tf.random.set_seed(rand)
orig_plt_params = plt.rcParams
sns.set()
cb_mdl = CatBoostClassifier(iterations=500, learning_rate=0.5, depth=8
)
fitted_cb_mdl = cb_mdl.fit(X_train, y_train, verbose=False)
y_test_cb_pred = fitted_cb_mdl .predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve

# Make predictions for the test data
y_test_cb_pred = fitted_cb_mdl.predict(X_test)

# Confusion Matrix
cf_matrix = confusion_matrix(y_test, y_test_cb_pred)
print("Confusion Matrix:\n", cf_matrix)

# Accuracy
accuracy = accuracy_score(y_test, y_test_cb_pred)
print("Accuracy:", accuracy)

# ROC Curve
auc = roc_auc_score(y_test, y_test_cb_pred)
fpr, tpr, thresholds = roc_curve(y_test, y_test_cb_pred)

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

idx1 = 2 # Caucasian
idx2 = 503 # African-American
idx3 = 57 # Hispanic
eval_idxs = X_test.index.isin([idx1, idx2, idx3])
X_test_evals = X_test[eval_idxs]
eval_compare_df = pd.concat([\
pd.DataFrame({'y':y_test[eval_idxs]},\
index=[idx3, idx2, idx1]),\
pd.DataFrame({'y_pred':y_test_cb_pred[eval_idxs]},\
index=[idx3, idx2, idx1]),\
X_test_evals], axis=1).transpose()
eval_compare_df
print("eval_compare_df\n",eval_compare_df)

!pip install alibi
from alibi.utils.mapping import ohe_to_ord, ord_to_ohe
from alibi.explainers import AnchorTabular
from alibi.explainers import CEM
from alibi.explainers import CounterFactualProto

class_names = ['Low Risk', 'Medium/High Risk']
X_test_eval = np.expand_dims(X_test.values[X_test.\
index.get_loc(idx1)], axis=0)
print("X_test_eval\n",X_test_eval)

cat_vars_ohe = {5: 2, 7: 5, 12: 9}
print(ohe_to_ord(X_test_eval, cat_vars_ohe)[0])

category_map = {
5: ['Female', 'Male'], 6: ['African-American', 'Asian', 'Caucasian',\
'Hispanic', 'Native American', 'Other'],
7: ['Felony 1st Degree', 'Felony 2nd Degree',\
'Felony 3rd Degree', 'Felony 7th Degree',\
'Misdemeanor 1st Degree', 'Misdemeanor 2nd Degree',\
'Misdemeanor 3rd Degree', 'Other Charge Degree']}

category_map_ohe = {5: ['Not Female', 'Female'], 6: ['Not Male', 'Male'],\
7:['Not African American', 'African American'],\
8:['Not Asian', 'Asian'], 9:['Not Caucasian', 'Caucasian'],\
10:['Not Hispanic', 'Hispanic'],\
11:['Not Native American', 'Native American'],\
12:['Not Other Race', 'Other Race'],\
13:['Not Felony 1st Level', 'Felony 1st Level'],\
14:['Not Felony 2nd Level', 'Felony 2nd Level'],\
15:['Not Felony 3rd Level', 'Felony 3rd Level'],\
16:['Not Felony 7th Level', 'Felony 7th Level'],\
17:['Not Misdemeanor 1st Deg', 'Misdemeanor 1st Deg'],\
18:['Not Misdemeanor 2nd Deg', 'Misdemeanor 2nd Deg'],\
19:['Not Misdemeanor 3rd Deg', 'Misdemeanor 3rd Deg'],\
20:['Not Other Charge Degree', 'Other Charge Degree']}

predict_cb_fn = lambda x: fitted_cb_mdl.predict_proba(x)

# from anchor import AnchorTabular
anchor_cb_explainer = AnchorTabular(predict_cb_fn, X_train.columns,\
categorical_names=category_map_ohe)
anchor_cb_explainer.fit(X_train.values)
anchor_cb_explanation =\
anchor_cb_explainer.explain(X_test.loc[idx1].values, threshold=0.9,\
seed=rand)

print('Prediction: %s' %\
class_names[anchor_cb_explainer.predictor(X_test.loc[idx1].values)[0]])
print('Precision: %.3f' % anchor_cb_explanation.precision)
print('Coverage: %.3f' % anchor_cb_explanation.coverage)

print('Anchor: %s' % (' AND\r\n\t'.join(anchor_cb_explanation.anchor)))

print('Anchor: %s' % (' AND\r\n\t'.join(anchor_cb_explanation.anchor)))

from alibi.utils.mapping import ohe_to_ord, ord_to_ohe
from alibi.explainers import AnchorTabular
from alibi.explainers import CEM
from alibi.explainers import CounterFactualProto, CounterfactualProto

idx1 = 2 # Caucasian
idx2 = 503 # African-American
idx3 = 57 # Hispanic

eval_idxs = X_test.index.isin([idx1, idx2, idx3])
X_test_evals = X_test[eval_idxs]
eval_compare_df = pd.concat([\
pd.DataFrame({'y':y_test[eval_idxs]},\
index=[idx1, idx2, idx3]),\
pd.DataFrame({'y_pred':y_test_cb_pred[eval_idxs]},\
index=[idx1, idx2, idx3]),\
X_test_evals], axis=1).transpose()
eval_compare_df
print("eval_compare_df\n",eval_compare_df)

X_test_eval =np.expand_dims(X_test.values[X_test.\
index.get_loc(idx3)], axis=0)
print("X_test_eval\n",X_test_eval)

cat_vars_ohe = {5: 2, 7: 5, 12: 9}
category_map = {
5: ['Female', 'Male'],
7: ['African-American', 'Asian', 'Caucasian',\
'Hispanic', 'Other'],
12: ['Felony 1st Degree', 'Felony 2nd Degree',\
'Felony 3rd Degree', 'Felony 7th Degree',\
'Misdemeanor 1st Degree', 'Misdemeanor 2nd Degree',\
'Misdemeanor 3rd Degree', 'Other Charge Degree']
}
feature_names = ['age', 'juv_fel_count', 'juv_misd_count',\
'juv_other_count', 'priors_count',
'sex', 'race', 'c_charge_degree']
category_map_ohe = {5: ['Not Female', 'Female'], 6: ['Not Male', 'Male'],\
7:['Not African American', 'African American'],\
8:['Not Asian', 'Asian'],
9:['Not Caucasian', 'Caucasian'],\
10:['Not Hispanic', 'Hispanic'],\
11:['Not Other Race', 'Other Race'],\
12:['Not Felony 1st Level', 'Felony 1st Level'],\
13:['Not Felony 2nd Level', 'Felony 2nd Level'],\
14:['Not Felony 3rd Level', 'Felony 3rd Level'],\
15:['Not Felony 7th Level', 'Felony 7th Level'],\
16:['Not Misdemeanor 1st Deg', 'Misdemeanor 1st Deg'],\
17:['Not Misdemeanor 2nd Deg', 'Misdemeanor 2nd Deg'],\
18:['Not Misdemeanor 3rd Deg', 'Misdemeanor 3rd Deg'],\
19:['Not Other Charge Degree', 'Other Charge Degree']}

predict_cb_fn = lambda x: 1 - fitted_cb_mdl.predict_proba(x)

feature_range = (X_train.values.min(axis=0).reshape(1,21).astype(np.float32),\
X_train.values.max(axis=0).reshape(1,21).astype(np.float32))

import tensorflow as tf
from alibi.explainers import CounterfactualProto

# Disable eager execution
tf.compat.v1.disable_eager_execution()

# Assuming the rest of your code remains the same
cf_nn_explainer = CounterfactualProto(predict_cb_fn,
                                       X_test_eval.shape,
                                       max_iterations=100,
                                       feature_range=feature_range,
                                       beta=.1,
                                       theta=100,
                                       use_kdtree=True)

cf_nn_explainer.fit(X_test.values, d_type='abdm-mvdm')
cf_nn_explanation = cf_nn_explainer.explain(X_test_eval)

print("cf_nn_explanation.data['cf']['X']\n",cf_nn_explanation.data['cf']['X'])

orig = X_test_eval
counterfactual = cf_nn_explanation.data['cf']['X']
delta = orig - counterfactual
feature_names = list(X_test.columns)
for i in range(len(feature_names)):
    if np.abs(delta[0,i]) > 1e-4:
        f = feature_names[i]
        print('{}: {} -> {}'.format(f, orig[0,i],counterfactual[0,i]))